{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regis University MSDS 686 Final Project\n",
        "# Fake News Classification\n",
        "\n",
        "This notebook trains a model to classify articles as real or fake news. This issue is more relevant than ever. While internet literacy has always been a problem, there has been a growing number of false stories being presented as truthful online. The goal of this notebook is to train a model that can successfully detect which stories are false.\n",
        "\n",
        "The notebook is organized into the following sections: \n",
        "1. Importing dependencies and data\n",
        "2. Creating dataset\n",
        "3. Models\n",
        "  * Bag of words with TF-IDF\n",
        "  * LSTM\n",
        "4. Summary & Conclusion"
      ],
      "metadata": {
        "id": "kztd3H-cgQ1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dependencies and Data\n",
        "## Dependencies"
      ],
      "metadata": {
        "id": "TuupngO4jyVf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zrp8IOdqgCGB"
      },
      "outputs": [],
      "source": [
        "# utilities\n",
        "import os\n",
        "import shutil\n",
        "# data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# text processing\n",
        "import string\n",
        "import re\n",
        "# machine learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers, backend, initializers, Input\n",
        "from tensorflow.keras.layers import TextVectorization, Bidirectional, LSTM, LayerNormalization, MultiHeadAttention, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "# seed notebook\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtain data from Kaggle\n",
        "\n",
        "The data used for this task is from the Fake and real news dataset on Kaggle, posted by Clement Bisaillon. The dataset can be found at: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset.\n",
        "\n",
        "The data contains 4 features: the title, text, date, and subject. The dataset is (nearly) balanced between true and false articles, and the dates of the articles range from March 2015 to February 2018. However, the model will be trained solely on the text of the articles."
      ],
      "metadata": {
        "id": "REyU9lGwo-lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kaggle\n",
        "! pip install kaggle -q\n",
        "\n",
        "# Upload previously downloaded Kaggle API token\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Make directory for kaggle and copy token there, change permissions so owner has read/write access\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Check that kaggle is installed correctly\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "Ks3Te1TlpTKu",
        "outputId": "f36375bb-68e4-4a95-e9ab-889c75b00a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-521523dc-f65c-4daa-9e70-d0772d1a5398\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-521523dc-f65c-4daa-9e70-d0772d1a5398\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "ref                                                             title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                       COVID-19 Dataset                                      5MB  2022-11-13 15:47:17           7647        234  1.0              \n",
            "madhurpant/world-deaths-and-causes-1990-2019                    World Deaths and Causes (1990 - 2019)               442KB  2022-11-29 07:09:27           1484         36  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                       Salary Prediction                                     3MB  2022-11-16 13:52:31           4922        111  1.0              \n",
            "swaptr/fifa-world-cup-2022-statistics                           FIFA World Cup 2022 Team Data                        15KB  2022-12-11 22:08:40           1168         35  0.9117647        \n",
            "thedevastator/how-much-sleep-do-americans-really-get            How Much Sleep Do Americans Really Get?               8KB  2022-11-25 09:13:12           1004         33  1.0              \n",
            "elmoallistair/population-by-age-group-2021                      Population by Age Group                               7KB  2022-11-23 14:50:05            628         23  1.0              \n",
            "akshaydattatraykhare/data-for-admission-in-the-university       Data for Admission in the University                  4KB  2022-10-27 11:05:45           8522        184  1.0              \n",
            "aguado/bike-rental-data-set-uci                                 Bike Rental Data Set - UCI                          124KB  2022-11-30 10:31:04            907         31  1.0              \n",
            "dbarteaux99/stable-diffusion-1-5                                Stable Diffusion 1.5 (normal and EMAonly) with vae    7GB  2022-10-23 15:40:29            146         20  0.9375           \n",
            "whenamancodes/predict-diabities                                 Predict Diabetes                                      9KB  2022-11-09 12:18:49           5122         93  1.0              \n",
            "prosperchuks/health-dataset                                     Diabetes, Hypertension and Stroke Prediction        597KB  2022-11-23 10:04:03           2210         52  1.0              \n",
            "mvieira101/global-cost-of-living                                Global Cost of Living                                 1MB  2022-12-03 16:37:53           1754         42  0.9705882        \n",
            "thedevastator/cancer-patients-and-air-pollution-a-new-link       Lung Cancer Prediction                               7KB  2022-11-14 13:40:40           3151         71  1.0              \n",
            "thedevastator/nike-usa-products-prices-descriptions-and-custom  Nike Products: Prices, Descriptions, Reviews         47KB  2022-11-28 07:01:00           1395         30  1.0              \n",
            "notshrirang/spotify-million-song-dataset                        Spotify Million Song Dataset                         21MB  2022-11-21 16:48:45           1723         39  1.0              \n",
            "theakhilb/layoffs-data-2022                                     Layoffs Dataset 2022                                101KB  2022-12-08 12:03:06            933         26  1.0              \n",
            "akshaydattatraykhare/diabetes-dataset                           Diabetes Dataset                                      9KB  2022-10-06 08:55:25          22918        584  1.0              \n",
            "catherinerasgaitis/mxmh-survey-results                          Music & Mental Health Survey Results                 22KB  2022-11-21 10:03:12           1860         41  1.0              \n",
            "malayvyas/usa-gdp-dataset-19612021                              USA GDP Growth Dataset 1961-2021                     10KB  2022-12-01 16:10:46            457         25  0.88235295       \n",
            "sulphatet/daily-weather-data-40-years                           daily weather data: 40 years                          1MB  2022-11-30 17:51:22            472         25  0.7647059        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "! kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset\n",
        "\n",
        "# Unzip dataset\n",
        "! unzip fake-and-real-news-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQWPLvMSs3Js",
        "outputId": "5dc2db20-8817-486b-80b6-bf3a2e2be5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fake-and-real-news-dataset.zip to /content\n",
            "100% 41.0M/41.0M [00:01<00:00, 40.3MB/s]\n",
            "100% 41.0M/41.0M [00:01<00:00, 26.8MB/s]\n",
            "Archive:  fake-and-real-news-dataset.zip\n",
            "  inflating: Fake.csv                \n",
            "  inflating: True.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_stories = pd.read_csv('Fake.csv')\n",
        "false_stories = pd.read_csv('True.csv')"
      ],
      "metadata": {
        "id": "btISR9Jku-xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_stories.head()"
      ],
      "metadata": {
        "id": "FM6KnbdPvYn9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6e0f49b5-88b9-41dc-9326-d20df393624c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
              "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
              "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
              "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
              "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
              "\n",
              "                                                text subject  \\\n",
              "0  Donald Trump just couldn t wish all Americans ...    News   \n",
              "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
              "2  On Friday, it was revealed that former Milwauk...    News   \n",
              "3  On Christmas day, Donald Trump announced that ...    News   \n",
              "4  Pope Francis used his annual Christmas Day mes...    News   \n",
              "\n",
              "                date target  \n",
              "0  December 31, 2017   true  \n",
              "1  December 31, 2017   true  \n",
              "2  December 30, 2017   true  \n",
              "3  December 29, 2017   true  \n",
              "4  December 25, 2017   true  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57dec6f7-74e2-4ef3-9b0b-9846bf99aa08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 25, 2017</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57dec6f7-74e2-4ef3-9b0b-9846bf99aa08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57dec6f7-74e2-4ef3-9b0b-9846bf99aa08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57dec6f7-74e2-4ef3-9b0b-9846bf99aa08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "false_stories.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Us7baF0KkUMS",
        "outputId": "6a8178a4-034c-4f0d-a419-0289b740923b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  As U.S. budget fight looms, Republicans flip t...   \n",
              "1  U.S. military to accept transgender recruits o...   \n",
              "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
              "3  FBI Russia probe helped by Australian diplomat...   \n",
              "4  Trump wants Postal Service to charge 'much mor...   \n",
              "\n",
              "                                                text       subject  \\\n",
              "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
              "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
              "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
              "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
              "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
              "\n",
              "                 date target  \n",
              "0  December 31, 2017    fake  \n",
              "1  December 29, 2017    fake  \n",
              "2  December 31, 2017    fake  \n",
              "3  December 30, 2017    fake  \n",
              "4  December 29, 2017    fake  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3492c182-bfe1-46f6-b581-5dc82b744d82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
              "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U.S. military to accept transgender recruits o...</td>\n",
              "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
              "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
              "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
              "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3492c182-bfe1-46f6-b581-5dc82b744d82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3492c182-bfe1-46f6-b581-5dc82b744d82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3492c182-bfe1-46f6-b581-5dc82b744d82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Dataset \n",
        "While this dataset is not particularly large and could fit in memory, I'll store it in the session memory and pull data from the appropriate directories in batches. Separate directories are created for the training, validation, and testing data, and each directory contains folders for each class (true and false). Approximately 60% of the data is used for training, 20% for validation, and 20% for testing."
      ],
      "metadata": {
        "id": "hxQOImys34JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign target label\n",
        "true_stories['target'] = 'true'\n",
        "false_stories['target'] = 'fake'\n",
        "\n",
        "# Create train, validation, and test folders\n",
        "os.makedirs('train')\n",
        "os.makedirs('val')\n",
        "os.makedirs('test')\n",
        "\n",
        "# Create subfolders for true and fake news stories\n",
        "for category in ['true', 'fake']:\n",
        "  os.makedirs('train/'+category)\n",
        "  os.makedirs('val/'+category)\n",
        "  os.makedirs('test/'+category)"
      ],
      "metadata": {
        "id": "2VSFaLBhwCK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use 60% of data for training, 20% for validation, 20% for testing\n",
        "train_ratio = int(0.6 * len(true_stories))\n",
        "val_ratio = int(0.2 * len(true_stories))\n",
        "\n",
        "# Slice data\n",
        "train_true = true_stories[:train_ratio]\n",
        "train_false = false_stories[:train_ratio]\n",
        "\n",
        "val_true = true_stories[train_ratio:train_ratio + val_ratio]\n",
        "val_false = false_stories[train_ratio:train_ratio + val_ratio]\n",
        "\n",
        "test_true = true_stories[train_ratio + val_ratio:]\n",
        "test_false = false_stories[train_ratio + val_ratio:]\n",
        "\n",
        "# Utility function to place news articles into respective folders as .txt files\n",
        "def move_articles(data, base_path):\n",
        "  category = data['target'].iloc[0]\n",
        "  i = 0\n",
        "  for article in data['text']:\n",
        "    with open(base_path + category + '/' + str(i) + '.txt', 'w', encoding='utf-8') as my_article:\n",
        "      i += 1\n",
        "      my_article.write(article)\n",
        "\n",
        "# Move articles to respective folders\n",
        "move_articles(train_true, 'train/')\n",
        "move_articles(train_false, 'train/')\n",
        "move_articles(val_true, 'val/')\n",
        "move_articles(val_false, 'val/')\n",
        "move_articles(test_true, 'test/')\n",
        "move_articles(test_false, 'test/')"
      ],
      "metadata": {
        "id": "h3a9kIr50AQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate that files are in correct location\n",
        "batch_size = 32\n",
        "train_flow = keras.utils.text_dataset_from_directory('train/')\n",
        "val_flow = keras.utils.text_dataset_from_directory('val/')\n",
        "test_flow = keras.utils.text_dataset_from_directory('test/')"
      ],
      "metadata": {
        "id": "l2hsNOVMocOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423c0197-b679-4846-faf7-2c23d32afd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28176 files belonging to 2 classes.\n",
            "Found 9392 files belonging to 2 classes.\n",
            "Found 7330 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting a Common-Sense Baseline"
      ],
      "metadata": {
        "id": "gCW846btoWxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_true = len(true_stories)\n",
        "num_false = len(false_stories)\n",
        "num_articles = num_true + num_false\n",
        "\n",
        "print(f'Percent true: {num_true / num_articles * 100}%')\n",
        "print(f'Percent false: {num_false / num_articles * 100}%')"
      ],
      "metadata": {
        "id": "3NyHwGJkoVCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0248a090-dfb5-4a44-a1d6-b840af36659e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percent true: 52.29854336496058%\n",
            "Percent false: 47.70145663503943%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With 52% of the stories being true and 48% of the stories being false, the data is nearly evenly split. A common-sense baseline to beat would be an accuracy of 50%. \n",
        "\n",
        "The data is now ready to be fed to the models. I'll start with a bag of words approach and implement TF-IDF.\n",
        "\n",
        "# Model 1: Bag of Words with TF-IDF\n",
        "This model takes a bag of words approach and implements TF-IDF. Before training, the data is vectorized with a vocabulary size of 20,000 words using the TextVectorization() function in Keras. This Keras implementation allows us to do a few things in one step:\n",
        "* Typical text pre-processing steps such as removing whitespace and puctuation and converting to lowercase are handled in this step\n",
        "* Bi-grams are generated from the text\n",
        "* The text is represented as TF-IDF scores"
      ],
      "metadata": {
        "id": "IJfSbAfFrTli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define text vectorizer\n",
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode='tf_idf',\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    split='whitespace')\n",
        "\n",
        "# Compute vocabulary from train dataset\n",
        "vocab = train_flow.map(lambda x, y: x)\n",
        "text_vectorization.adapt(vocab)\n",
        "\n",
        "# Apply vectorization to text data\n",
        "tf_idf_bigram_train = train_flow.map(lambda x, y: (text_vectorization(x), y))\n",
        "tf_idf_bigram_val = val_flow.map(lambda x, y: (text_vectorization(x), y))\n",
        "tf_idf_bigram_test = test_flow.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "# Define model\n",
        "def tf_idf_bigram(max_tokens=20000):\n",
        "  backend.clear_session()\n",
        "  inputs = keras.Input(shape=(max_tokens,))\n",
        "  x = layers.Dense(units=16, activation='relu') (inputs)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(1, activation='sigmoid') (x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  model.compile(optimizer='rmsprop',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "# Initialize model with callbacks\n",
        "m1 = tf_idf_bigram()\n",
        "callbacks = [keras.callbacks.EarlyStopping(monitor= 'val_accuracy',\n",
        "                                           patience = 3,\n",
        "                                           restore_best_weights = True)]\n",
        "\n",
        "# Fit data to model\n",
        "m1.fit(tf_idf_bigram_train,\n",
        "       validation_data = tf_idf_bigram_val,\n",
        "       epochs = 20,\n",
        "       callbacks = callbacks)\n",
        "\n",
        "# Evaluate model on test data\n",
        "m1.evaluate(tf_idf_bigram_test)"
      ],
      "metadata": {
        "id": "tTVNz0UDr_kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b26658-69f7-483b-a300-0a652e609440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "881/881 [==============================] - 15s 14ms/step - loss: 0.1956 - accuracy: 0.9519 - val_loss: 0.1436 - val_accuracy: 0.9674\n",
            "Epoch 2/20\n",
            "881/881 [==============================] - 12s 14ms/step - loss: 0.0821 - accuracy: 0.9802 - val_loss: 0.1495 - val_accuracy: 0.9639\n",
            "Epoch 3/20\n",
            "881/881 [==============================] - 12s 14ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 0.2223 - val_accuracy: 0.9766\n",
            "Epoch 4/20\n",
            "881/881 [==============================] - 14s 16ms/step - loss: 0.0514 - accuracy: 0.9835 - val_loss: 0.1534 - val_accuracy: 0.9751\n",
            "Epoch 5/20\n",
            "881/881 [==============================] - 12s 14ms/step - loss: 0.0451 - accuracy: 0.9839 - val_loss: 0.2231 - val_accuracy: 0.9774\n",
            "Epoch 6/20\n",
            "881/881 [==============================] - 12s 14ms/step - loss: 0.0428 - accuracy: 0.9846 - val_loss: 0.2532 - val_accuracy: 0.9772\n",
            "Epoch 7/20\n",
            "881/881 [==============================] - 12s 14ms/step - loss: 0.0417 - accuracy: 0.9849 - val_loss: 0.2357 - val_accuracy: 0.9795\n",
            "Epoch 8/20\n",
            "881/881 [==============================] - 12s 14ms/step - loss: 0.0339 - accuracy: 0.9911 - val_loss: 0.2765 - val_accuracy: 0.9772\n",
            "Epoch 9/20\n",
            "881/881 [==============================] - 13s 14ms/step - loss: 0.0350 - accuracy: 0.9911 - val_loss: 0.2757 - val_accuracy: 0.9691\n",
            "Epoch 10/20\n",
            "881/881 [==============================] - 12s 14ms/step - loss: 0.0355 - accuracy: 0.9918 - val_loss: 0.2855 - val_accuracy: 0.9776\n",
            "230/230 [==============================] - 2s 10ms/step - loss: 0.2226 - accuracy: 0.9578\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22258391976356506, 0.9578444957733154]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: LSTM with Pre-Trained GLOVE Embeddings\n",
        "This model uses a LSTM recurrent neural network. This allows for a better understanding of context in the text and removes unnecessary data via the forget gate. \n",
        "\n",
        "This model leverages pre-trained GLOVE word embeddings. This choice was made due to the relatively small size of the dataset--it is unlikely that deriving word embeddings from the training data would provide a higher accuracy than using GLOVE embeddings. The text vectorizer is also re-defined to not use TF-IDF."
      ],
      "metadata": {
        "id": "8eAiwA_P5SUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings manually uploaded to session storage\n",
        "path_to_glove = 'glove.6B.100d.txt'\n",
        "\n",
        "# Dictionary to index embeddings\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove) as f:\n",
        "  # store words and array of vector coefficients as key-value pair\n",
        "  for line in f:\n",
        "    word, coefs = line.split(maxsplit=1)\n",
        "    coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "# Redefine text vectorizer\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    split='whitespace',\n",
        "    output_mode='int',\n",
        ")\n",
        "\n",
        "# Vectorize text\n",
        "vocab = train_flow.map(lambda x, y: x)\n",
        "text_vectorization.adapt(vocab)\n",
        "vocab = text_vectorization.get_vocabulary()\n",
        "\n",
        "# Index words and save as dict\n",
        "word_index = dict(zip(vocab, range(len(vocab))))\n",
        "\n",
        "# Create embedding matrix with shape (max tokens, embedding dimension)\n",
        "max_tokens = 20000\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "# Iterate through word index\n",
        "for word, i in word_index.items():\n",
        "  # Save the GLOVE embeddings to the embedding matrix for the first 20000 tokens \n",
        "  if i < max_tokens:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Apply vectorization to text data\n",
        "lstm_train = train_flow.map(lambda x, y: (text_vectorization(x), y))\n",
        "lstm_val = val_flow.map(lambda x, y: (text_vectorization(x), y))\n",
        "lstm_test = test_flow.map(lambda x, y: (text_vectorization(x), y))"
      ],
      "metadata": {
        "id": "zT10wflAyyRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm():\n",
        "  inputs = keras.Input(shape=(None,), dtype='int64')\n",
        "  embedded = layers.Embedding(max_tokens,\n",
        "                              embedding_dim,\n",
        "                              embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix),\n",
        "                              trainable=False,\n",
        "                              mask_zero=True) (inputs)\n",
        "  x = layers.Bidirectional(LSTM(32)) (embedded)\n",
        "  x = layers.Dropout(0.5) (x)\n",
        "  outputs = layers.Dense(1, activation='sigmoid') (x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  model.compile(optimizer='rmsprop',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "m2 = lstm()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(monitor= 'val_accuracy',\n",
        "                                           patience = 3,\n",
        "                                           restore_best_weights = True)]\n",
        "\n",
        "m2.fit(lstm_train, validation_data=lstm_val, epochs=20, callbacks=callbacks)\n",
        "m2.evaluate(lstm_test)"
      ],
      "metadata": {
        "id": "7VBPpSQGil22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ba92c4-8425-4188-ebe3-36e79a4a8750"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "881/881 [==============================] - 1373s 2s/step - loss: 0.0506 - accuracy: 0.9874 - val_loss: 0.0134 - val_accuracy: 0.9987\n",
            "Epoch 2/20\n",
            "881/881 [==============================] - 1302s 1s/step - loss: 0.0168 - accuracy: 0.9972 - val_loss: 0.0098 - val_accuracy: 0.9990\n",
            "Epoch 3/20\n",
            "881/881 [==============================] - 1342s 2s/step - loss: 0.0126 - accuracy: 0.9981 - val_loss: 0.0100 - val_accuracy: 0.9987\n",
            "Epoch 4/20\n",
            "881/881 [==============================] - 1419s 2s/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0061 - val_accuracy: 0.9993\n",
            "Epoch 5/20\n",
            "881/881 [==============================] - 1321s 1s/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.0058 - val_accuracy: 0.9991\n",
            "Epoch 6/20\n",
            "881/881 [==============================] - 1346s 2s/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
            "Epoch 7/20\n",
            "881/881 [==============================] - 1370s 2s/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0071 - val_accuracy: 0.9989\n",
            "230/230 [==============================] - 130s 559ms/step - loss: 0.0082 - accuracy: 0.9986\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.008170774206519127, 0.9986357688903809]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSb5cVGFALq1",
        "outputId": "1073256c-afa6-48c9-eb09-a08b30f8002d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZxoXCjiAO7-",
        "outputId": "6ae1ffcf-001a-4a2a-9b28-4b51e6543d4f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         2000000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               34048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,034,113\n",
            "Trainable params: 34,113\n",
            "Non-trainable params: 2,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate all models side by side\n",
        "m1.evaluate(tf_idf_bigram_test)\n",
        "m2.evaluate(lstm_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNERFrzXfWbp",
        "outputId": "50d83a39-b311-43be-f6d4-0bb3e98c1f1d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230/230 [==============================] - 3s 11ms/step - loss: 0.2226 - accuracy: 0.9578\n",
            "230/230 [==============================] - 123s 537ms/step - loss: 0.0082 - accuracy: 0.9986\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.008170774206519127, 0.9986357688903809]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary & Conclusion\n",
        "This notebook trained 2 models to distinguish between true and false news stories. The methods used included a bag of words approach utilizing bi-grams and TF-IDF and LSTM with GLOVE embeddings.\n",
        "\n",
        "Both models performed well, outperforming the common-sense baseline of 50%. The bag of words approach achieved a score of 95.78%, and the LSTM model achieved a score of 99.86%"
      ],
      "metadata": {
        "id": "fRNecNr9bLiu"
      }
    }
  ]
}